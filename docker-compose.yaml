version: '3.8'

services:
  msls:
    image: msls
    container_name: msls
    env_file:
      - .env
    build:
      context: .
      dockerfile: Dockerfile  # 앞에서 작성한 Dockerfile 경로
      args:
        USER_NAME: "${USER_NAME}"
        USER_ID: "${USER_ID}"
        GROUP_NAME: "${GROUP_NAME}"
        GROUP_ID: "${GROUP_ID}"
    # restart: unless-stopped
    ports:
      - "${PORT_HOST}:${PORT_APP}"  # API 통신을 위한 포트 개방
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia  # nvidia-docker를 사용하기 위한 설정
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      # - HF_TOKEN=${HF_TOKEN} # Hugging Face 접근 토큰이 필요한 경우
    stdin_open: true  # 표준 입력 열기 (interactive mode)
    tty: true         # 터미널 모드 사용
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    #   start_period: 60s

    volumes:
      - ${PATH_PROJECT_LOCAL}:${PATH_PROJECT_VIRTUAL}:Z  # 로컬 디렉토리 볼륨 마운트
      - ${PATH_DATA_LOCAL}:${PATH_DATA_VIRTUAL}:Z  # 로컬 디렉토리 볼륨 마운트
      - ${PATH_LOG_LOCAL}:${PATH_LOG_VIRTUAL}:Z  # 로컬 디렉토리 볼륨 마운트
      - ${PATH_MODEL_LOCAL}:${PATH_MODEL_VIRTUAL}:Z  # 로컬 디렉토리 볼륨 마운트
      - ~/.cache/huggingface:/root/.cache/huggingface
    # command: >
    #   bash -c "uv sync && uv add uvicorn"